from fastapi import FastAPI

from app.api.routes import router

app = FastAPI(title="SQL Copilot API",     version="1.0.0",
    docs_url="/swagger",
    redoc_url=None,
    swagger_ui_parameters={
        "tryItOutEnabled": True,
        "tagsSorter": "alpha",
        "operationsSorter": "alpha",
        "displayRequestDuration": True,
        # "defaultModelsExpandDepth": -1
    })

app.include_router(router)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True, use_colors=True)

"""
TODO [CORE]:
  - [ ] ğŸ¯ Implement centralized error handling middleware
        â€¢ Catch, normalize & format all exceptions
        â€¢ Ensure graceful degradation on agent errors
  - [ ] ğŸ” Add authentication & authorization
        â€¢ JWT introspection
        â€¢ Role-based access checks
        â€¢ Token error handling (expired, malformed)
  - [ ] ğŸ“ˆ Integrate structured logging & correlation
        â€¢ Requestâ€‘ID propagation across all layers
        â€¢ Agentâ€‘level logs with trace metadata
        â€¢ Include correlation IDs in streaming outputs

TODO [API]:
  1. `/query` Orchestration
      - [ ] Input validation & prompt sanitization
      - [ ] Orchestrate full agent pipeline via `MasterAgent`
      - [ ] Stream intermediate/final results (chunked, SSE or WebSocket)
      - [ ] Handle partial failures (e.g., SQL generated, but execution failed)
      - [ ] Return structured response: `{ sql, rows, explainPlan, summary }`
  2. (Future) Agentâ€‘specific debug/test endpoints:
      - [ ] `/metadata`, `/understand`, `/generate-sql`, etc.
      - [ ] Enable isolated agent invocation & inspection for dev/debug

TODO [AGENTS]:
  - [ ] ğŸ“Š `MetadataAgent`
        â€¢ Fetch, normalize & cache OpenMetadata schemas
        â€¢ Support hybrid context (schema + usage logs if available)
  - [ ] ğŸ§  `DynamicRAGAgent`
        â€¢ Construct RAG pipeline dynamically for metadata injection
        â€¢ Inject context into prompts based on user question type
  - [ ] ğŸ§  `MemoryAgent`
        â€¢ Persist & retrieve conversation state
        â€¢ Use vector-based RAG over past queries, feedback, corrections
        â€¢ Manage context window limits with priority trimming
        â€¢ Support memory types: ephemeral, long-term, episodic
  - [ ] ğŸ¤– `UnderstandingAgent`
        â€¢ NL â†’ intent & entity extraction (e.g., metrics, filters)
        â€¢ Detect query type: ask, compare, aggregate, optimize
  - [ ] ğŸ“ `SQLGenerationAgent`
        â€¢ Schema-aware SQL generation via templates or LLM
        â€¢ Handle user intent, joins, aggregations, filters
  - [ ] âœ… `ValidationAgent`
        â€¢ Check syntax, SQL-injection, reserved keywords
        â€¢ Enforce whitelist/blacklist of operations (e.g., no DDL)
  - [ ] âš™ï¸ `ExecutionAgent`
        â€¢ Execute SQL (`RUN`) and explain (`EXPLAIN`) using MCP server
        â€¢ Capture runtime errors and DB feedback
  - [ ] ğŸ” `PlanAnalysisAgent`
        â€¢ Parse EXPLAIN plans
        â€¢ Identify inefficiencies (e.g., seq scan, missing index)
        â€¢ Recommend or trigger optimization
  - [ ] ğŸ§ª `OptimizationAgent`
        â€¢ Iterate on SQL â†’ EXPLAIN loop
        â€¢ Use MCP server to test & validate improvements
        â€¢ Summarize final rationale for changes
  - [ ] ğŸ”„ `PostProcessingAgent`
        â€¢ Type coercion, null handling, pagination, formatting
  - [ ] ğŸ `PackagingAgent`
        â€¢ Assemble `{ sql, rows, summary, plan, trace }` for return
        â€¢ Attach metadata like source tables, tokens used, latency
  - [ ] ğŸ” `RetrievalAgent` *(optional)*
        â€¢ Vector search for prior queries, docs, past results
        â€¢ Use Heystack or FAISS-backed embedding store
  - [ ] ğŸ¤ `MasterAgent` (Orchestrator)
        â€¢ Topâ€‘level controller for agent delegation
        â€¢ Can pause, inject clarifying sub-questions, or retry
        â€¢ Streams intermediate + final agent results to client
        â€¢ Supports dry-run (simulate without execution)

TODO [DEV EXPERIENCE]:
  - [ ] ğŸ§° Agent Dev Harness
        â€¢ CLI/mini UI to test individual agents with mock inputs
        â€¢ Snapshot memory state, step-through pipelines
        â€¢ Log intermediate agent outputs and traces

TODO [INFRA]:
  - [ ] ğŸ› ï¸ LangFlow integration: map workflows to orchestrator
  - [ ] ğŸ”„ Experiment with Dify as an alternative orchestration layer
  - [ ] ğŸ—„ï¸ Stand up `MCP` server
        â€¢ Support for Postgres, Snowflake, MySQL
        â€¢ Handle SQL execution + EXPLAIN interface + caching
        â€¢ Auth layer & logging built-in
  - [ ] âš™ï¸ Configure OpenMetadata client
        â€¢ Externalize URL, auth token in `config.py`
        â€¢ Enable schema preloading and polling

TODO [NEXT STEPS]:
  - [ ] ğŸ§ª Testing strategy
        â€¢ Unit tests for each agent
        â€¢ Integration tests for multi-agent flows
        â€¢ End-to-end tests for `/query` (streaming & sync modes)
  - [ ] ğŸ”„ CI/CD pipeline
        â€¢ Format, lint & type-check (Black, myPy, Checkstyle)
        â€¢ Dependency & SQLâ€‘i security scans
        â€¢ Auto-deploy pipeline (dev â†’ staging â†’ prod)
  - [ ] ğŸ“Š Metrics & Monitoring
        â€¢ Per-agent success/failure & latency
        â€¢ MasterAgent orchestration metrics
        â€¢ DB query success/failure counts
        â€¢ Alerting on error thresholds
  - [ ] ğŸ“¡ Observability & Tracing
        â€¢ OpenTelemetry-based tracing across agents
        â€¢ Correlate logs, metrics, traces via request ID
        â€¢ Enable distributed trace visualization (e.g., Jaeger)
  - [ ] ğŸ“š Documentation
        â€¢ OpenAPI spec (including streaming event model)
        â€¢ Agent & memory customization how-tos
        â€¢ Architecture & troubleshooting guides
        â€¢ Quickstart + deployment instructions

MERMAID DIAGRAM:
(See `docs/architecture.md`, or paste below to visualize agent interactions)
"""
